#!/usr/bin/env python
import numpy as np
import matplotlib.pyplot as plt
import random, math, networkx as nx
from mesa import Agent, Model
from mesa.space import MultiGrid
from mesa.time import RandomActivation
from DisasterModelNew import DisasterModel

############################################
# Run model and collect time-series and histogram data.
############################################
def run_model_collect_timeseries(num_ticks=300):
    model = DisasterModel(
        share_exploitative=0.5,
        share_of_disaster=0.2,
        initial_trust=0.5,
        initial_ai_trust=0.75,
        number_of_humans=50,
        share_confirming=0.5,
        disaster_dynamics=2,
        shock_probability=0.1,
        shock_magnitude=2,
        trust_update_mode="average",
        exploitative_correction_factor=1.0,
        width=50,
        height=50
    )
    ticks = []
    trust_data = []   # Each element: (exp_human, exp_ai, expl_human, expl_ai)
    unmet_needs = []  # Each element: unmet needs count at that tick.
    calls_data = []   # Each element: (calls_exp_human, calls_exp_ai, calls_expl_human, calls_expl_ai)
    
    for t in range(num_ticks):
        model.step()
        ticks.append(t)
        # Record trust: compute averages per agent type.
        exp_human = []
        exp_ai = []
        expl_human = []
        expl_ai = []
        for agent in model.humans.values():
            human_vals = [v for key, v in agent.trust.items() if key.startswith("H_")]
            ai_vals = [v for key, v in agent.trust.items() if key.startswith("A_")]
            if agent.agent_type == "exploitative":
                if human_vals:
                    exp_human.append(np.mean(human_vals))
                if ai_vals:
                    exp_ai.append(np.mean(ai_vals))
            else:
                if human_vals:
                    expl_human.append(np.mean(human_vals))
                if ai_vals:
                    expl_ai.append(np.mean(ai_vals))
        trust_data.append((
            np.mean(exp_human) if exp_human else 0,
            np.mean(exp_ai) if exp_ai else 0,
            np.mean(expl_human) if expl_human else 0,
            np.mean(expl_ai) if expl_ai else 0
        ))
        # Unmet needs: count grid cells with level>=4 that got no token in this tick.
        unmet = 0
        for pos, level in model.disaster_grid.items():
            if level >= 4 and model.tokens_this_tick.get(pos, 0) == 0:
                unmet += 1
        unmet_needs.append(unmet)
        # Record calls data: Divide human calls by 3.
        if model.calls_data:
            calls = model.calls_data[-1]
            # calls: (calls_exp_human, calls_exp_ai, calls_expl_human, calls_expl_ai)
            debiased = (calls[0]/3, calls[1], calls[2]/3, calls[3])
            calls_data.append(debiased)
    
    # Also, record token distributions from the final state.
    tokens_need = []      # For cells in need (level>=4)
    tokens_incorrect = [] # For cells not in need (level<=2)
    for pos, level in model.disaster_grid.items():
        if level >= 4:
            tokens = model.assistance_exploit.get(pos, 0) + model.assistance_explor.get(pos, 0)
            tokens_need.append(tokens)
        if level <= 2:
            tokens_err = model.assistance_incorrect_exploit.get(pos, 0) + model.assistance_incorrect_explor.get(pos, 0)
            tokens_incorrect.append(tokens_err)
    
    return ticks, trust_data, unmet_needs, calls_data, tokens_need, tokens_incorrect

############################################
# Aggregate time-series data from multiple runs.
############################################
num_runs = 5
num_ticks = 300

all_trust = []   # shape: (num_runs, num_ticks, 4)
all_unmet = []   # shape: (num_runs, num_ticks)
all_calls = []   # shape: (num_runs, num_ticks, 4)
all_tokens_need = []      # list of arrays from each run (variable length)
all_tokens_incorrect = [] # list of arrays from each run

for run in range(num_runs):
    ticks, trust_ts, unmet_ts, calls_ts, tokens_need, tokens_incorrect = run_model_collect_timeseries(num_ticks)
    all_trust.append(trust_ts)
    all_unmet.append(unmet_ts)
    all_calls.append(calls_ts)
    all_tokens_need.extend(tokens_need)         # aggregate all token counts across runs
    all_tokens_incorrect.extend(tokens_incorrect)

all_trust = np.array(all_trust)
all_unmet = np.array(all_unmet)
all_calls = np.array(all_calls)
ticks_arr = np.array(ticks)

def aggregate_timeseries(data):
    mean = np.mean(data, axis=0)
    p25 = np.percentile(data, 25, axis=0)
    p75 = np.percentile(data, 75, axis=0)
    # Compute error as absolute difference from mean.
    return mean, np.abs(mean - p25), np.abs(p75 - mean)

trust_mean, trust_err_lower, trust_err_upper = aggregate_timeseries(all_trust)  # shape: (num_ticks, 4)
unmet_mean, unmet_err_lower, unmet_err_upper = aggregate_timeseries(all_unmet)  # shape: (num_ticks,)
calls_mean, calls_err_lower, calls_err_upper = aggregate_timeseries(all_calls)  # shape: (num_ticks, 4)

############################################
# Plot time-series dynamics.
############################################
plt.figure(figsize=(16,10))
# Trust evolution.
plt.subplot(2,2,1)
labels = ["Exp-Human", "Exp-AI", "Expl-Human", "Expl-AI"]
for i in range(4):
    plt.plot(ticks_arr, trust_mean[:, i], label=labels[i])
    plt.fill_between(ticks_arr, trust_mean[:, i] - trust_err_lower[:, i], trust_mean[:, i] + trust_err_upper[:, i], alpha=0.3)
plt.xlabel("Tick")
plt.ylabel("Average Trust")
plt.title("Trust Evolution by Agent Type")
plt.legend()

# Unmet needs.
plt.subplot(2,2,2)
plt.plot(ticks_arr, unmet_mean, marker='o', markersize=3)
plt.fill_between(ticks_arr, unmet_mean - unmet_err_lower, unmet_mean + unmet_err_upper, alpha=0.3)
plt.xlabel("Tick")
plt.ylabel("Unmet Needs\n(Cells with level>=4 and no tokens)")
plt.title("Unmet Needs Evolution")

# Calls data.
plt.subplot(2,2,3)
call_labels = ["Exp-Human Calls", "Exp-AI Calls", "Expl-Human Calls", "Expl-AI Calls"]
for i in range(4):
    plt.plot(ticks_arr, calls_mean[:, i], label=call_labels[i])
    plt.fill_between(ticks_arr, calls_mean[:, i] - calls_err_lower[:, i], calls_mean[:, i] + calls_err_upper[:, i], alpha=0.3)
plt.xlabel("Tick")
plt.ylabel("Information Request Calls (Human calls debiased)")
plt.title("Calls by Agent Type")
plt.legend()

plt.tight_layout()
plt.show()

############################################
# Plot histograms for token distributions (averaged over runs).
############################################
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.hist(all_tokens_need, bins=20, color='skyblue', edgecolor='black')
plt.xlabel("Tokens Delivered")
plt.ylabel("Frequency")
plt.title("Histogram: Tokens Delivered to Cells in Need (Level>=4)")

plt.subplot(1,2,2)
plt.hist(all_tokens_incorrect, bins=20, color='salmon', edgecolor='black')
plt.xlabel("Tokens Delivered")
plt.ylabel("Frequency")
plt.title("Histogram: Tokens Delivered Incorrectly (Level<=2)")

plt.tight_layout()
plt.show()
